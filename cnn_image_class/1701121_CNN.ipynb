{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "\n",
    "\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the data set\n",
    "# Keep adding more images and classifiers here\n",
    "# Now: load csv files, Future: Pull from Hermes\n",
    "\n",
    "# Now:\n",
    "# load all image files from a directory\n",
    "# add dataframe with number classifier\n",
    "\n",
    "# Future:\n",
    "# Query Hermes API to call all images by certain date\n",
    "# construct dataframe to be three columns: image, plugin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this function to create an image+classifer 2-column df\n",
    "def create_im_classifer_df(path, classifer):\n",
    "\n",
    "    # Puts all files from a directory (path) into list called files\n",
    "    #path = \"C:\\\\Users\\\\RiggsSc\\\\Documents\\\\LAM\\\\D_Science\\\\SIM\\\\CNN_image_class\\\\PR\\\\\"\n",
    "    files = os.listdir(path)\n",
    "\n",
    "    # Subsets the files list to only include files with the last four extension of tif\n",
    "    files_tiff = [f for f in files if f[-3:] == 'tif']\n",
    "\n",
    "    new_images = []\n",
    "    new_classifer = []\n",
    "    for image in files_tiff:\n",
    "        im = cv2.imread(path + image)\n",
    "        gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "        new_images.append(gray)\n",
    "        new_classifer.append(classifer)\n",
    "    \n",
    "    # Creates a df, one column is the grayscale images, the other a classifer\n",
    "    new_data_df = pd.DataFrame({'images': new_images,\n",
    "                                'classifer': new_classifer})\n",
    "    return new_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to append new image/classifer df to main dataset df\n",
    "def increase_dataset_df(main_data_set, new_df, col_name):\n",
    "    \n",
    "    rescaled_im = []\n",
    "    for image in new_df[col_name]:\n",
    "        # compare shapes\n",
    "        if image.shape == main_data_set[col_name][0].shape:\n",
    "            pass\n",
    "        else:\n",
    "            # make the new_df have the same shape as the old df\n",
    "            # *CURRENTLY ONLY WORKS if main_data_set.shape > new_df.shape\n",
    "            image = cv2.copyMakeBorder(image,\n",
    "                                       0,\n",
    "                                       main_data_set[col_name][0].shape[0] - image.shape[0],\n",
    "                                       0,\n",
    "                                       main_data_set[col_name][1].shape[1] - image.shape[1],\n",
    "                                       cv2.BORDER_CONSTANT,value=0)\n",
    "            #print(image.shape, main_data_set[col_name][0].shape)\n",
    "        rescaled_im.append(image)    \n",
    "      \n",
    "    rescaled_im_df = pd.DataFrame({'images': rescaled_im,\n",
    "                                'classifer': new_df['classifer']})\n",
    "    \n",
    "    return main_data_set.append(rescaled_im_df, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# builds test/train set from a 2-column image/classifer df\n",
    "def df_to_test_train_split(df): \n",
    "\n",
    "    # dim_row & dim_col are dimensions of the images\n",
    "    dim_row = df['images'][0].shape[0]\n",
    "    dim_col = df['images'][0].shape[1]\n",
    "        \n",
    "    # shape X\n",
    "    X=np.empty(shape=(len(df['images']), dim_row, dim_col)) #create empty 3D tensor\n",
    "    \n",
    "    for i in range(len(df['images'])): # turn df column into 3D tensor\n",
    "        X[i] = df['images'][i]\n",
    "        \n",
    "    X = X.reshape(X.shape[0], dim_row, dim_col, 1)\n",
    "    X = X.astype('float32') # change pixel values into floats\n",
    "    X /= 255 # divide by the the 0-255 bit number\n",
    "    #print(X[0])\n",
    "\n",
    "    # shape y\n",
    "    le = preprocessing.LabelEncoder() # Create a label (category) encoder object\n",
    "    le.fit(df['classifer']) # fit the encoder to the df column\n",
    "    #print(list(le.classes_)) # print out the classes\n",
    "    #print(list(le.inverse_transform([2, 2, 1])))# Convert some integers into their category names\n",
    "    y = np.array(le.transform(df['classifer'])) # apply the fitted encoder to the df column, turn into vector\n",
    "    y = np_utils.to_categorical(y)\n",
    "\n",
    "\n",
    "    # test train X,y\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.85)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build the CNN\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Design a CNN\n",
    "model.add(Conv2D(3, (9, 9), padding='valid', input_shape=(1908, 2048, 1))) #fixed?\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(2, (9, 9)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3)) #fixed?\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Fit your model\n",
    "model.fit(X_train, y_train, batch_size=2, epochs=1,    #fixed?\n",
    "          verbose=1, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PR = create_im_classifer_df(path='C:\\\\Users\\\\RiggsSc\\\\Documents\\\\LAM\\\\D_Science\\\\SIM\\\\CNN_image_class\\\\PR\\\\', classifer='PR')\n",
    "BSE = create_im_classifer_df(path='C:\\\\Users\\\\RiggsSc\\\\Documents\\\\LAM\\\\D_Science\\\\SIM\\\\CNN_image_class\\\\BSE\\\\', classifer='BSE')\n",
    "STI = create_im_classifer_df(path='C:\\\\Users\\\\RiggsSc\\\\Documents\\\\LAM\\\\D_Science\\\\SIM\\\\CNN_image_class\\\\STI\\\\', classifer='STI')\n",
    "STI2 = create_im_classifer_df(path='C:\\\\Users\\\\RiggsSc\\\\Documents\\\\LAM\\\\D_Science\\\\SIM\\\\CNN_image_class\\\\STI2\\\\', classifer='STI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = increase_dataset_df(STI, BSE, 'images')\n",
    "df2 = increase_dataset_df(df1, PR, 'images')\n",
    "main_data_set_df = increase_dataset_df(df2, STI2, 'images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = df_to_test_train_split(main_data_set_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now and Future:\n",
    "# Open main data set\n",
    "# append the new data to the larger data set\n",
    "# zip and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now:\n",
    "# function: opens dataset\n",
    "#           parese df, reshapes X,y data\n",
    "\n",
    "# Future:\n",
    "# function: opens dataset\n",
    "#           3rd column to df plugin to a number\n",
    "#           parses df, reshapes X,y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now and Future:\n",
    "# Build the test,train\n",
    "# Build the CNN\n",
    "# Run model\n",
    "# Save model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
